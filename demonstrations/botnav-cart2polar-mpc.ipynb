{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1e6620",
   "metadata": {},
   "source": [
    "## Model-predictive control for mobile robot navigation\n",
    "\n",
    "Wouter Kouw, last update: 06-06-2024\n",
    "\n",
    "### Robot dynamics\n",
    "\n",
    "Consider a mobile robot that moves according to:\n",
    "\n",
    "$$\\underbrace{\\begin{bmatrix} x_{1,k} \\\\ x_{2,k} \\\\ \\dot{x}_{1,k} \\\\ \\dot{x}_{2,k} \\end{bmatrix}}_{z_k} = \\underbrace{\\begin{bmatrix} 1 & 0 & \\Delta t & 0 \\\\ 0 & 1 & 0 & \\Delta t \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}}_{A} \\underbrace{\\begin{bmatrix} x_{1,k-1} \\\\ x_{2,k-1} \\\\ \\dot{x}_{1,k-1} \\\\ \\dot{x}_{2,k-1} \\end{bmatrix}}_{z_{k-1}} + \\underbrace{\\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\\\ \\Delta t & 0 \\\\ 0 & \\Delta t \\end{bmatrix}}_{B} \\underbrace{\\begin{bmatrix} u_{1,k} \\\\ u_{2,k}\\end{bmatrix}}_{u_k} + q_k \\, .$$\n",
    "\n",
    "Process noise is white, $q_k \\sim \\mathcal{N}(0, Q)$, with \n",
    "\n",
    "$$Q = \\begin{bmatrix} \\frac{\\Delta t^3}{3} \\rho_1 & 0 & \\frac{\\Delta t^2}{2} \\rho_1 & 0 \\\\\n",
    "                      0 & \\frac{\\Delta t^3}{3} \\rho_2 & 0 & \\frac{\\Delta t^2}{2} \\rho_2 \\\\\n",
    "                      \\frac{\\Delta t^2}{2} \\rho_1 & 0 & \\Delta t \\rho_1 & 0 \\\\\n",
    "                      0 & \\frac{\\Delta t^2}{2} \\rho_2 & 0 & \\Delta t \\rho_2 \\end{bmatrix} \\, .$$\n",
    "\n",
    "### Observations: polar coordinates from beacon\n",
    "\n",
    "In the middle of a training area, there is a beacon that reports range and angle to the robot. This will allow it to infer its position in the field through a polar-to-cartesian transformation:\n",
    "\n",
    "$$\\begin{align}\n",
    "y_{1,k} &= g_1(z_k) = \\sqrt{x_{1,k}^2 + x_{2,k}^2} \\\\\n",
    "y_{2,k} &= g_2(z_k) = \\mathrm{atan}(x_{1,k}, x_{2,k}) \\, ,\n",
    "\\end{align}$$\n",
    "\n",
    "where $\\mathrm{atan}$ refers to the arctangent. We denote this as:\n",
    "\n",
    "$$y_k = g(z_k) + r_k$$\n",
    "\n",
    "where $r_k$ is measurement noise. \n",
    "\n",
    "### Model-predictive controller\n",
    "\n",
    "To control the robot, we unroll the dynamical system T steps into the future, i.e., from $t = (k+1, \\dots, k+T). We then form an objective function based on how close the predicted states are to the desired state\n",
    "\n",
    "$$J(u_t) = \\sum_{t=1}^T \\big((Az_{t-1} + Bu_t) - z_{*} \\big)^{\\top} F \\big((Az_{t-1} + Bu_t) - z_{*}\\big) + \\eta u_t^2$$\n",
    "\n",
    "starting from the current state estimate $z_0 = \\mathbb{E}[z_k]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d06cbd",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8350ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()\n",
    "using Revise\n",
    "using Colors\n",
    "using Optim\n",
    "using ForwardDiff\n",
    "using ProgressMeter\n",
    "using LinearAlgebra\n",
    "using ControlSystems\n",
    "using Distributions\n",
    "using StatsPlots\n",
    "using Plots\n",
    "default(label=\"\", grid=false, linewidth=3, markersize=3, margin=10Plots.pt)\n",
    "includet(\"../Robots.jl\"); using. Robots\n",
    "includet(\"../ModelPredictiveControllers.jl\"); using. ModelPredictiveControllers\n",
    "includet(\"../util.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4abe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time\n",
    "Δt = 0.5\n",
    "len_trial = 10\n",
    "tsteps = range(0, step=Δt, length=len_trial)\n",
    "len_horizon = 5;\n",
    "     \n",
    "# Nonlinear observation\n",
    "g(x::AbstractVector) = [sqrt(x[1]^2 + x[2]^2), atan(x[2],x[1])]\n",
    "\n",
    "# Setpoint (desired observation)\n",
    "z_star = [0.0, 1., 0.0, 0.0]\n",
    "\n",
    "# Parameters\n",
    "σ = 1e-2\n",
    "ρ = [1e-2, 1e-2]\n",
    "η = 0.0\n",
    "\n",
    "# Limits of controller\n",
    "u_lims = (-1.0, 1.0)\n",
    "opts = Optim.Options(time_limit=20)\n",
    "\n",
    "# Cost matrix\n",
    "F = [1. 0. 0.  0.;\n",
    "     0. 1. 0.  0.;\n",
    "     0. 0. 0.  0.;\n",
    "     0. 0. 0.  0.]\n",
    "\n",
    "# Initial state\n",
    "z_0 = [0.0, -1., 0., 0.]\n",
    "\n",
    "# Initial belief\n",
    "m_0 = z_0\n",
    "S_0 = 0.5diagm(ones(4));\n",
    "\n",
    "fbot = FieldBot(g, ρ, σ=σ, Δt=Δt, control_lims=u_lims)\n",
    "mpcontrol = MPController(z_star, g, ρ, σ=σ; η=η, Δt=Δt, time_horizon=len_horizon, cost_matrix=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63764f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocate\n",
    "z_est = (zeros(4,len_trial), zeros(4,4,len_trial))\n",
    "z_pln = (zeros(len_trial, 4,len_horizon), zeros(len_trial, 4,4,len_horizon))\n",
    "y_pln = (zeros(len_trial, 2,len_horizon), zeros(len_trial, 2,2,len_horizon))\n",
    "z_sim = zeros(4,len_trial)\n",
    "y_sim = zeros(2,len_trial)\n",
    "u_sim = zeros(2,len_trial)\n",
    "F_MPC = zeros(len_trial)\n",
    "J_MPC = zeros(len_trial)\n",
    "\n",
    "# Initial state\n",
    "z_sim[:,1] = z_0\n",
    "z_est[1][:,1] = m_0\n",
    "z_est[2][:,:,1] = S_0\n",
    "\n",
    "# Start recursion\n",
    "m_kmin1 = m_0\n",
    "S_kmin1 = S_0\n",
    "\n",
    "# Initialize policy\n",
    "policy = zeros(len_trial, 2, len_horizon)\n",
    "\n",
    "@showprogress for k in 1:len_trial\n",
    "    \n",
    "    if k > 1\n",
    "    \n",
    "        \"Interact with environment\"\n",
    "\n",
    "        # Update system with selected control\n",
    "        y_sim[:,k], z_sim[:,k] = update(fbot, z_sim[:,k-1], u_sim[:,k-1])\n",
    "                \n",
    "        \"State estimation\"\n",
    "        \n",
    "        m_k_pred, S_k_pred = predict(mpcontrol, m_kmin1, S_kmin1, u_sim[:,k-1])\n",
    "        m_k,S_k = correct(mpcontrol, y_sim[:,k], m_k_pred, S_k_pred, approx=\"ET2\")\n",
    "        \n",
    "        # Compute model evidence\n",
    "        F_MPC[k] = evidence(mpcontrol, y_sim[:,k], m_k, S_k, approx=\"ET2\")\n",
    "        J_MPC[k] = -logpdf(MvNormal(goal[1], goal[2]), y_sim[:,k])\n",
    "        \n",
    "        # Store state estimates\n",
    "        z_est[1][:,k] = m_k\n",
    "        z_est[2][:,:,k] = S_k\n",
    "\n",
    "    else\n",
    "        m_k = m_0\n",
    "        S_k = S_0\n",
    "    end\n",
    "    \n",
    "    \"Planning\"\n",
    "    \n",
    "    # Single-argument objective\n",
    "    J(u::AbstractVector) = objective(mpcontrol, u, (m_k,S_k))\n",
    "    \n",
    "    # Call minimizer using constrained L-BFGS procedure\n",
    "    results = Optim.optimize(J, u_lims[1], u_lims[2], zeros(2len_horizon), Fminbox(LBFGS()), opts; autodiff=:forward)\n",
    "    \n",
    "    # Extract minimizing control\n",
    "    policy[k,:,:] = reshape(Optim.minimizer(results), (2,len_horizon))\n",
    "    \n",
    "    # Planning\n",
    "    planned_states, planned_obs = planned_trajectory(mpcontrol, policy[k,:,:], (m_k,S_k))\n",
    "    z_pln[1][k,:,:]   = planned_states[1]\n",
    "    z_pln[2][k,:,:,:] = planned_states[2] \n",
    "    y_pln[1][k,:,:]   = planned_obs[1]\n",
    "    y_pln[2][k,:,:,:] = planned_obs[2]\n",
    "    \n",
    "    # Execute first planned action only\n",
    "    u_sim[:,k] = policy[k,:,1]\n",
    "   \n",
    "    # Update recursion\n",
    "    m_kmin1 = m_k\n",
    "    S_kmin1 = S_k\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44801fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tJ_MPC = sum(J_MPC)\n",
    "plot(J_MPC, title=\"Total -logp(y|y_*) (MPC) = $tJ_MPC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbfc457",
   "metadata": {},
   "outputs": [],
   "source": [
    "tF_MPC = sum(F_MPC)\n",
    "plot(F_MPC, title=\"Total F (MPC) = $tF_MPC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f233210",
   "metadata": {},
   "outputs": [],
   "source": [
    "tU = sum(abs.(u_sim[:]))\n",
    "plot(u_sim', title=\"Total control cost = $tU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7c0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(policy[1,:,:]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = [-2., 2.]\n",
    "yl = [-1.5, 3.5]\n",
    "\n",
    "anim = @animate for k in 3:len_trial\n",
    "    p301 = plot(size=(800,800), legend=:topleft, aspect_ratio=:equal, ylabel=\"position y\", xlabel=\"position x\", xlims=xl, ylims=yl)\n",
    "    scatter!([z_0[1]], [z_0[2]], color=\"blue\", label=\"start\", markersize=5)\n",
    "    scatter!([z_star[1]], [z_star[2]], color=\"red\", label=\"goal state\", markersize=5)\n",
    "    \n",
    "    plot!(z_sim[1,2:k], z_sim[2,2:k], c=\"blue\", label=\"true\", alpha=0.5)\n",
    "    plot!(z_est[1][1,2:k], z_est[1][2,2:k], c=\"purple\", label=\"inferred\", alpha=0.5)\n",
    "    covellipse!(z_est[1][1:2,k], z_est[2][1:2,1:2,k], n_std=1, color=\"purple\", linewidth=0, fillalpha=0.3)\n",
    "    \n",
    "    plot!(z_pln[1][k,1,:], z_pln[1][k,2,:], c=\"orange\", label=\"planned\")\n",
    "    for j in 1:len_horizon\n",
    "        covellipse!(z_pln[1][k,1:2,j], z_pln[2][k,1:2,1:2,j], n_std=1, color=\"orange\", linewidth=0, fillalpha=0.3)\n",
    "    end\n",
    "end\n",
    "gif(anim, \"animations/cart2polar-experiment-MPC-path.gif\", fps=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = [-2., 2.]\n",
    "yl = [-1.5, 3.5]\n",
    "\n",
    "k = 1\n",
    "\n",
    "p91 = plot(size=(400,300), legend=:topleft, ylabel=\"position y\", xlabel=\"position x\", xlims=xl, ylims=yl)\n",
    "scatter!([0.0], [0.0], color=\"black\", marker=:ltriangle, label=\"sensor station\", markersize=8)\n",
    "scatter!([z_0[1]], [z_0[2]], color=\"green\", label=\"start state\", markersize=8)\n",
    "scatter!([z_star[1]], [z_star[2]], color=\"red\", label=\"goal state\", markersize=8)\n",
    "\n",
    "plot!([z_sim[1,1:k]], [z_sim[2,1:k]], c=\"blue\", marker=\".\", label=\"system states\", alpha=1., markersize=5)\n",
    "scatter!([z_est[1][1,k]], [z_est[1][2,k]], c=\"purple\", label=\"state estimate\", alpha=1., markersize=8)\n",
    "covellipse!(z_est[1][1:2,k], z_est[2][1:2,1:2,k], n_std=1, color=\"purple\", linewidth=1, fillalpha=0.3)\n",
    "\n",
    "plot!(z_pln[1][k,1,:], z_pln[1][k,2,:], marker=\".\", c=\"orange\", markersize=5, label=\"planned states\")\n",
    "for j in 1:len_horizon\n",
    "    covellipse!(z_pln[1][k,1:2,j], z_pln[2][k,1:2,1:2,j], n_std=1, color=\"orange\", linewidth=1, fillalpha=0.1)\n",
    "end \n",
    "plot!(dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453f0f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"figures/cart2polar-mpc-trajectory-k$k.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "p92 = plot(size=(400,300), legend=:topleft, aspect_ratio=:equal, ylabel=\"position y\", xlabel=\"position x\", xlims=xl, ylims=yl)\n",
    "scatter!([0.0], [0.0], color=\"black\", marker=:ltriangle, label=\"sensor station\", markersize=8)\n",
    "scatter!([z_0[1]], [z_0[2]], color=\"green\", label=\"start state\", markersize=8)\n",
    "scatter!([z_star[1]], [z_star[2]], color=\"red\", label=\"goal state\", markersize=8)\n",
    "\n",
    "plot!([z_sim[1,1:k]], [z_sim[2,1:k]], c=\"blue\", marker=\".\", label=\"system states\", alpha=1., markersize=5)\n",
    "scatter!([z_est[1][1,k]], [z_est[1][2,k]], c=\"purple\", label=\"state estimate\", alpha=1., markersize=8)\n",
    "covellipse!(z_est[1][1:2,k], z_est[2][1:2,1:2,k], n_std=1, color=\"purple\", linewidth=1, fillalpha=0.3)\n",
    "\n",
    "plot!([z_est[1][1,k]; z_pln[1][k,1,:]], [z_est[1][2,k]; z_pln[1][k,2,:]], marker=\".\", c=\"orange\", markersize=5, label=\"planned states\")\n",
    "for j in 1:len_horizon\n",
    "    covellipse!(z_pln[1][k,1:2,j], z_pln[2][k,1:2,1:2,j], n_std=1, color=\"orange\", linewidth=1, fillalpha=0.1)\n",
    "end \n",
    "plot!(dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967bd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"figures/cart2polar-mpc-trajectory-k$k.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74770a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len_trial\n",
    "\n",
    "p93 = plot(size=(400,300), legend=:topleft, aspect_ratio=:equal, ylabel=\"position y\", xlabel=\"position x\", xlims=xl, ylims=yl)\n",
    "scatter!([0.0], [0.0], color=\"black\", marker=:ltriangle, label=\"sensor station\", markersize=8)\n",
    "scatter!([z_0[1]], [z_0[2]], color=\"green\", label=\"start state\", markersize=8)\n",
    "scatter!([z_star[1]], [z_star[2]], color=\"red\", label=\"goal state\", markersize=8)\n",
    "\n",
    "plot!([z_sim[1,1:k]], [z_sim[2,1:k]], c=\"blue\", marker=\".\", label=\"system states\", alpha=1., markersize=5)\n",
    "\n",
    "plot!(z_est[1][1,1:k], z_est[1][2,1:k], c=\"purple\", marker=\".\", label=\"state estimates\", alpha=1., markersize=5)\n",
    "for j in 1:len_trial\n",
    "    covellipse!(z_est[1][1:2,j], z_est[2][1:2,1:2,j], n_std=1, color=\"purple\", linewidth=1, fillalpha=0.1)\n",
    "end\n",
    "plot!(dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca523c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"figures/cart2polar-mpc-trajectory-trial.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330db682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
