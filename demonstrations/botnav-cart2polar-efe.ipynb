{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1e6620",
   "metadata": {},
   "source": [
    "## Expected Free Energy minimization for mobile robot navigation\n",
    "\n",
    "Wouter Kouw, last update: 06-06-2024\n",
    "\n",
    "### Dynamics\n",
    "\n",
    "Consider a mobile robot that moves according to:\n",
    "\n",
    "$$\\underbrace{\\begin{bmatrix} x_{1,k} \\\\ x_{2,k} \\\\ \\dot{x}_{1,k} \\\\ \\dot{x}_{2,k} \\end{bmatrix}}_{z_k} = \\underbrace{\\begin{bmatrix} 1 & 0 & \\Delta t & 0 \\\\ 0 & 1 & 0 & \\Delta t \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}}_{A} \\underbrace{\\begin{bmatrix} x_{1,k-1} \\\\ x_{2,k-1} \\\\ \\dot{x}_{1,k-1} \\\\ \\dot{x}_{2,k-1} \\end{bmatrix}}_{z_{k-1}} + \\underbrace{\\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\\\ \\Delta t & 0 \\\\ 0 & \\Delta t \\end{bmatrix}}_{B} \\underbrace{\\begin{bmatrix} u_{1,k} \\\\ u_{2,k}\\end{bmatrix}}_{u_k} + q_k \\, .$$\n",
    "\n",
    "Process noise is white, $q_k \\sim \\mathcal{N}(0, Q)$, with \n",
    "\n",
    "$$Q = \\begin{bmatrix} \\frac{\\Delta t^3}{3} \\rho_1 & 0 & \\frac{\\Delta t^2}{2} \\rho_1 & 0 \\\\\n",
    "                      0 & \\frac{\\Delta t^3}{3} \\rho_2 & 0 & \\frac{\\Delta t^2}{2} \\rho_2 \\\\\n",
    "                      \\frac{\\Delta t^2}{2} \\rho_1 & 0 & \\Delta t \\rho_1 & 0 \\\\\n",
    "                      0 & \\frac{\\Delta t^2}{2} \\rho_2 & 0 & \\Delta t \\rho_2 \\end{bmatrix} \\, .$$\n",
    "\n",
    "### Observations: polar coordinates from beacon\n",
    "\n",
    "In the middle of a training area, there is a beacon that reports range and angle to the robot. This will allow it to infer its position in the field through a polar-to-cartesian transformation:\n",
    "\n",
    "$$\\begin{align}\n",
    "y_{1,k} &= g_1(z_k) = \\sqrt{x_{1,k}^2 + x_{2,k}^2} \\\\\n",
    "y_{2,k} &= g_2(z_k) = \\mathrm{atan}(x_{1,k}, x_{2,k}) \\, ,\n",
    "\\end{align}$$\n",
    "\n",
    "where $\\mathrm{atan}$ refers to the arctangent. We denote this as:\n",
    "\n",
    "$$y_k = g(z_k) + r_k$$\n",
    "\n",
    "where $r_k$ is measurement noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dfcf89",
   "metadata": {},
   "source": [
    "### Probabilistic model\n",
    "\n",
    "The above system can be captured with a probabibilistic state-space model of the form:\n",
    "\n",
    "$$\\begin{align}\n",
    "p(z_0) &= \\mathcal{N}(z_0 \\mid m_0, S_0) \\\\\n",
    "p(z_k \\mid z_{k-1}, u_k) &= \\mathcal{N}(z_k \\mid Az_{k-1} + Bu_k, Q) \\\\\n",
    "p(y_k \\mid z_k) &= \\mathcal{N}(y_k \\mid g(z_k), R) \\, .\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef5d478",
   "metadata": {},
   "source": [
    "### Gaussian approximation to likelihood\n",
    "\n",
    "The joint will be:\n",
    "$$\\begin{align}\n",
    "p(y_k, z_k ) &\\approx \\mathcal{N} \\big(\\begin{bmatrix} z_k \\\\ y_k \\end{bmatrix} \\mid \\begin{bmatrix} m_k \\\\ \\mu_k \\end{bmatrix}, \\begin{bmatrix} S_k & \\Gamma_k \\\\ \\Gamma_k^{\\top} & \\Sigma_k \\end{bmatrix} \\big) \n",
    "\\end{align}$$\n",
    "\n",
    "Because it is a Gaussian, it can be conditioned to:\n",
    "$$\\begin{align}\n",
    "p(y_k | z_k) &\\approx \\mathcal{N} \\big(y_k | \\mu_k + \\Gamma_k^{\\intercal} S_k^{-1}(x_k - m_k), \\Sigma_k - \\Gamma_k S_k^{-1} \\Gamma_k^{\\intercal} \\big)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e552a2d0",
   "metadata": {},
   "source": [
    "### Posterior predictive\n",
    "\n",
    "$$\\begin{align}\n",
    "p(y_k \\mid y_{1:k-1}) &= \\int p(y_k \\mid z_k) p(z_k \\mid y_{1:k-1}) dz_k \\\\\n",
    "&= \\int \\mathcal{N} \\big(\\begin{bmatrix} z_k \\\\ y_k \\end{bmatrix} \\mid \\begin{bmatrix} m_k \\\\ \\mu_k \\end{bmatrix}, \\begin{bmatrix} S_k & \\Gamma_k \\\\ \\Gamma_k^{\\top} & \\Sigma_k \\end{bmatrix} \\big) dz_k \\\\\n",
    "&= \\mathcal{N}(y_k \\mid \\mu_k, \\Sigma_k)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa98f4e",
   "metadata": {},
   "source": [
    "### Planning and control\n",
    "\n",
    "EFE Objective for a single time step:\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\mathcal{J}_k(u_t) = \\mathrm{C}  +  \\frac{1}{2} \\text{tr}\\big(S_{*}^{-1} ( \\Sigma_t + \\Sigma_{*} ) \\big)  +  \\frac{1}{2} \\ln \\frac{\\big|\\Sigma_t  -  \\Gamma^{\\intercal}_t \\bar{S}_t^{- 1} \\Gamma_t \\big|}{\\big| \\Sigma_t \\big|} \n",
    "\\end{align}$$\n",
    "\n",
    "Minimizing this objective for a time horizon of $T$ steps:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\hat{u} &= \\underset{\\bar{u} \\in \\mathcal{U}}{\\arg \\max} \\ q^{*}(\\bar{u}) \\\\\n",
    "&= \\underset{\\bar{u} \\in \\mathcal{U}}{\\arg \\min} \\sum_{t=1}^{T} \\mathcal{J}_k(u_t) - \\ln p(u_t)  \\, .\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d06cbd",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8350ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()\n",
    "using Revise\n",
    "using Colors\n",
    "using Optim\n",
    "using ForwardDiff\n",
    "using ProgressMeter\n",
    "using LinearAlgebra\n",
    "using ControlSystems\n",
    "using Distributions\n",
    "using StatsPlots\n",
    "using Plots\n",
    "default(label=\"\", grid=false, linewidth=3, markersize=3, margin=15Plots.pt)\n",
    "includet(\"../Robots.jl\"); using. Robots\n",
    "includet(\"../FreeEnergyAgents.jl\"); using. FreeEnergyAgents\n",
    "includet(\"../util.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4abe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time\n",
    "Δt = 0.2\n",
    "len_trial = 20\n",
    "tsteps = range(0, step=Δt, length=len_trial)\n",
    "len_horizon = 5;\n",
    "\n",
    "# Nonlinear observation\n",
    "g(x::AbstractVector) = [sqrt(x[1]^2 + x[2]^2), atan(x[2],x[1])]\n",
    "\n",
    "# Setpoint (desired observation)\n",
    "z_star = [0.0, .5, 0.0, 0.0]\n",
    "goal = (g(z_star), 0.5diagm(ones(2)))\n",
    "\n",
    "# Parameters\n",
    "σ = 1e-3\n",
    "ρ = [1e-2, 1e-2]\n",
    "η = 0.0\n",
    "\n",
    "# Limits of controller\n",
    "u_lims = (-1.0, 1.0)\n",
    "opts = Optim.Options(time_limit=20)\n",
    "\n",
    "# Initial state\n",
    "z_0 = [0.0, -.5, 0., 0.]\n",
    "\n",
    "# Initial belief\n",
    "m_0 = z_0\n",
    "S_0 = 0.5diagm(ones(4));\n",
    "\n",
    "fbot  = FieldBot(g, ρ, σ=σ, Δt=Δt, control_lims=u_lims)\n",
    "agent = EFEAgent(goal, g, ρ, σ=σ; η=η, Δt=Δt, time_horizon=len_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d443dd2",
   "metadata": {},
   "source": [
    "### Model: EFE (ET2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb8c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocate\n",
    "z_est  = (zeros(4,len_trial), zeros(4,4,len_trial))\n",
    "z_pln  = (zeros(len_trial, 4,len_horizon), zeros(len_trial, 4,4,len_horizon))\n",
    "y_pln  = (zeros(len_trial, 2,len_horizon), zeros(len_trial, 2,2,len_horizon))\n",
    "z_sim  = zeros(4,len_trial)\n",
    "y_sim  = zeros(2,len_trial)\n",
    "u_sim  = zeros(2,len_trial)\n",
    "F_EFE2 = zeros(len_trial)\n",
    "J_EFE2 = zeros(len_trial)\n",
    "\n",
    "# Initial state\n",
    "z_sim[:,1] = z_0\n",
    "\n",
    "# Start recursion\n",
    "m_kmin1 = m_0\n",
    "S_kmin1 = S_0\n",
    "\n",
    "@showprogress for k in 2:len_trial\n",
    "    \n",
    "    \"Interact with environment\"\n",
    "\n",
    "    # Update system with selected control\n",
    "    y_sim[:,k], z_sim[:,k] = update(fbot, z_sim[:,k-1], u_sim[:,k-1])\n",
    "               \n",
    "    \"State estimation\"\n",
    "    \n",
    "    m_k_pred, S_k_pred = predict(agent, m_kmin1, S_kmin1, u_sim[:,k-1])\n",
    "    m_k,S_k = correct(agent, y_sim[:,k], m_k_pred, S_k_pred, approx=\"ET2\")\n",
    "    \n",
    "    # Compute model evidence\n",
    "    F_EFE2[k] = evidence(agent, y_sim[:,k], m_k_pred, S_k_pred, approx=\"ET2\")\n",
    "    J_EFE2[k] = -logpdf(MvNormal(goal[1], goal[2]), y_sim[:,k])\n",
    "    \n",
    "    # Store state estimates\n",
    "    z_est[1][:,k] = m_k\n",
    "    z_est[2][:,:,k] = S_k\n",
    "    \n",
    "    \"Planning\"\n",
    "    \n",
    "    # Single-argument objective\n",
    "    G(u::AbstractVector) = EFE(agent, u, (m_k,S_k), approx=\"ET2\")\n",
    "    \n",
    "    # Call minimizer using constrained L-BFGS procedure\n",
    "    results = Optim.optimize(G, u_lims[1], u_lims[2], zeros(2*len_horizon), Fminbox(LBFGS()), opts; autodiff=:forward)\n",
    "    \n",
    "    # Extract minimizing control\n",
    "    policy = reshape(Optim.minimizer(results), (2,len_horizon))\n",
    "    u_sim[:,k] = policy[:,1]\n",
    "\n",
    "    # Planning\n",
    "    planned_states, planned_obs = planned_trajectory(agent, policy, (m_k,S_k), approx=\"ET2\")\n",
    "    z_pln[1][k,:,:]   = planned_states[1]\n",
    "    z_pln[2][k,:,:,:] = planned_states[2] \n",
    "    y_pln[1][k,:,:]   = planned_obs[1]\n",
    "    y_pln[2][k,:,:,:] = planned_obs[2]\n",
    "   \n",
    "    # Update recursion\n",
    "    m_kmin1 = m_k\n",
    "    S_kmin1 = S_k\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = [-2., 2.]\n",
    "yl = [-1., 3.]\n",
    "\n",
    "anim = @animate for k in 3:len_trial\n",
    "    p301 = plot(size=(800,800), title=\"$k/$len_trial\", legend=:topleft, aspect_ratio=:equal, ylabel=\"position y\", xlabel=\"position x\", xlims=xl, ylims=yl)\n",
    "    scatter!([z_0[1]], [z_0[2]], color=\"blue\", label=\"start\", markersize=5)\n",
    "    scatter!([z_star[1]], [z_star[2]], color=\"red\", label=\"goal state\", markersize=5)\n",
    "    \n",
    "    plot!(z_sim[1,2:k], z_sim[2,2:k], c=\"blue\", label=\"true\", alpha=0.5)    \n",
    "    \n",
    "    plot!(z_est[1][1,2:k], z_est[1][2,2:k], c=\"purple\", label=\"inferred\", alpha=0.5)\n",
    "    covellipse!(z_est[1][1:2,k], z_est[2][1:2,1:2,k], n_std=1, color=\"purple\", linewidth=0, fillalpha=0.3)\n",
    "\n",
    "    plot!(z_pln[1][k,1,:], z_pln[1][k,2,:], c=\"orange\", label=\"planned\")\n",
    "    for j in 1:len_horizon\n",
    "        covellipse!(z_pln[1][k,1:2,j], z_pln[2][k,1:2,1:2,j], n_std=1, color=\"orange\", linewidth=0, fillalpha=0.3)\n",
    "    end\n",
    "end\n",
    "gif(anim, \"animations/cart2polar-experiment-EFE2-path.gif\", fps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ad66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p301 = plot(size=(800,500), legend=:topleft, ylabel=\"position y\", xlabel=\"position x\", xlims=xl, ylims=yl)\n",
    "scatter!([z_0[1]], [z_0[2]], color=\"green\", marker=:diamond, label=\"start\", markersize=8)\n",
    "scatter!([z_star[1]], [z_star[2]], color=\"green\", label=\"goal\", markersize=8)\n",
    "\n",
    "plot!(z_sim[1,:], z_sim[2,:], c=\"blue\", label=\"true\")    \n",
    "plot!(z_est[1][1,:], z_est[1][2,:], c=\"purple\", label=\"inferred\")\n",
    "\n",
    "for j in 1:len_trial\n",
    "    covellipse!(z_est[1][1:2,j], z_est[2][1:2,1:2,j], n_std=1, color=\"purple\", linewidth=0, fillalpha=0.1)\n",
    "end\n",
    "plot!()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"figures/cart2polar-experiment-EFE2-path.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1dcca",
   "metadata": {},
   "source": [
    "### Model: EFE (ET1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocate\n",
    "z_est  = (zeros(4,len_trial), zeros(4,4,len_trial))\n",
    "z_pln  = (zeros(len_trial, 4,len_horizon), zeros(len_trial, 4,4,len_horizon))\n",
    "y_pln  = (zeros(len_trial, 2,len_horizon), zeros(len_trial, 2,2,len_horizon))\n",
    "z_sim  = zeros(4,len_trial)\n",
    "y_sim  = zeros(2,len_trial)\n",
    "u_sim  = zeros(2,len_trial)\n",
    "F_EFE1 = zeros(len_trial)\n",
    "J_EFE1 = zeros(len_trial)\n",
    "\n",
    "# Initial state\n",
    "z_sim[:,1] = z_0\n",
    "\n",
    "# Start recursion\n",
    "m_kmin1 = m_0\n",
    "S_kmin1 = S_0\n",
    "\n",
    "# Initialize policy\n",
    "policy = zeros(2len_horizon)\n",
    "\n",
    "μ = zeros(2)  \n",
    "Σ = zeros(2,2)\n",
    "Γ = zeros(2,4)\n",
    "\n",
    "@showprogress for k in 2:len_trial\n",
    "    \n",
    "    \"Interact with environment\"\n",
    "\n",
    "    # Update system with selected control\n",
    "    y_sim[:,k], z_sim[:,k] = update(fbot, z_sim[:,k-1], u_sim[:,k-1])\n",
    "               \n",
    "    \"State estimation\"\n",
    "    \n",
    "    m_k_pred, S_k_pred = predict(agent, m_kmin1, S_kmin1, u_sim[:,k-1])\n",
    "    m_k,S_k = correct(agent, y_sim[:,k], m_k_pred, S_k_pred, approx=\"ET1\")\n",
    "    \n",
    "    # Compute model evidence\n",
    "    F_EFE1[k] = evidence(agent, y_sim[:,k], m_k, S_k, approx=\"ET2\")\n",
    "    J_EFE1[k] = -logpdf(MvNormal(goal[1], goal[2]), y_sim[:,k])\n",
    "    \n",
    "    # Store state estimates\n",
    "    z_est[1][:,k] = m_k\n",
    "    z_est[2][:,:,k] = S_k\n",
    "    \n",
    "    \"Planning\"\n",
    "    \n",
    "    # Single-argument objective\n",
    "    G(u::AbstractVector) = EFE(agent, u, (m_k,S_k), approx=\"ET1\")\n",
    "    \n",
    "    # Call minimizer using constrained L-BFGS procedure\n",
    "    results = Optim.optimize(G, u_lims[1], u_lims[2], zeros(2*len_horizon), Fminbox(LBFGS()), opts; autodiff=:forward)\n",
    "    \n",
    "    # Extract minimizing control\n",
    "    policy = reshape(Optim.minimizer(results), (2,len_horizon))\n",
    "    u_sim[:,k] = policy[:,1]\n",
    "\n",
    "    # Planning\n",
    "    planned_states, planned_obs = planned_trajectory(agent, policy, (m_k,S_k), approx=\"ET1\")\n",
    "    z_pln[1][k,:,:]   = planned_states[1]\n",
    "    z_pln[2][k,:,:,:] = planned_states[2] \n",
    "    y_pln[1][k,:,:]   = planned_obs[1]\n",
    "    y_pln[2][k,:,:,:] = planned_obs[2]\n",
    "   \n",
    "    # Update recursion\n",
    "    m_kmin1 = m_k\n",
    "    S_kmin1 = S_k\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = @animate for k in 3:len_trial\n",
    "    p301 = plot(size=(800,800), legend=:topleft, aspect_ratio=:equal, ylabel=\"position y\", xlabel=\"position x\", xlims=xl, ylims=yl)\n",
    "    scatter!([z_0[1]], [z_0[2]], color=\"blue\", label=\"start\", markersize=5)\n",
    "    scatter!([z_star[1]], [z_star[2]], color=\"red\", label=\"goal state\", markersize=5)\n",
    "    \n",
    "    plot!(z_sim[1,2:k], z_sim[2,2:k], c=\"blue\", label=\"true\", alpha=0.5)\n",
    "    plot!(z_est[1][1,2:k], z_est[1][2,2:k], c=\"purple\", label=\"inferred\", alpha=0.5)\n",
    "    covellipse!(z_est[1][1:2,k], z_est[2][1:2,1:2,k], n_std=1, color=\"purple\", linewidth=0, fillalpha=0.3)\n",
    "    \n",
    "    plot!(z_pln[1][k,1,:], z_pln[1][k,2,:], c=\"orange\", label=\"planned\")\n",
    "    for j in 1:len_horizon\n",
    "        covellipse!(z_pln[1][k,1:2,j], z_pln[2][k,1:2,1:2,j], n_std=1, color=\"orange\", linewidth=0, fillalpha=0.3)\n",
    "    end\n",
    "end\n",
    "gif(anim, \"animations/cart2polar-experiment-EFE1-path.gif\", fps=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b110675",
   "metadata": {},
   "outputs": [],
   "source": [
    "p301 = plot(size=(800,500), legend=:topleft, ylabel=\"position y\", xlabel=\"position x\", xlims=xl, ylims=yl)\n",
    "scatter!([z_0[1]], [z_0[2]], color=\"green\", marker=:diamond, label=\"start\", markersize=8)\n",
    "scatter!([z_star[1]], [z_star[2]], color=\"green\", label=\"goal\", markersize=8)\n",
    "\n",
    "plot!(z_sim[1,:], z_sim[2,:], c=\"blue\", label=\"true\")    \n",
    "plot!(z_est[1][1,:], z_est[1][2,:], c=\"purple\", label=\"inferred\")\n",
    "\n",
    "for j in 1:len_trial\n",
    "    covellipse!(z_est[1][1:2,j], z_est[2][1:2,1:2,j], n_std=1, color=\"purple\", linewidth=0, fillalpha=0.1)\n",
    "end\n",
    "plot!()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f954e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"figures/cart2polar-experiment-EFE1-path.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb2d3e3",
   "metadata": {},
   "source": [
    "### Model: EFER (ET2 risk only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758cd59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocate\n",
    "z_est  = (zeros(4,len_trial), zeros(4,4,len_trial))\n",
    "z_pln  = (zeros(len_trial, 4,len_horizon), zeros(len_trial, 4,4,len_horizon))\n",
    "y_pln  = (zeros(len_trial, 2,len_horizon), zeros(len_trial, 2,2,len_horizon))\n",
    "z_sim  = zeros(4,len_trial)\n",
    "y_sim  = zeros(2,len_trial)\n",
    "u_sim  = zeros(2,len_trial)\n",
    "F_EFER = zeros(len_trial)\n",
    "J_EFER = zeros(len_trial)\n",
    "\n",
    "# Initial state\n",
    "z_sim[:,1] = z_0\n",
    "\n",
    "# Start recursion\n",
    "m_kmin1 = m_0\n",
    "S_kmin1 = S_0\n",
    "\n",
    "# Initialize policy\n",
    "policy = zeros(2len_horizon)\n",
    "\n",
    "μ = zeros(2)  \n",
    "Σ = zeros(2,2)\n",
    "Γ = zeros(2,4)\n",
    "\n",
    "@showprogress for k in 2:len_trial\n",
    "    \n",
    "    \"Interact with environment\"\n",
    "\n",
    "    # Update system with selected control\n",
    "    y_sim[:,k], z_sim[:,k] = update(fbot, z_sim[:,k-1], u_sim[:,k-1])\n",
    "               \n",
    "    \"State estimation\"\n",
    "    \n",
    "    m_k_pred, S_k_pred = predict(agent, m_kmin1, S_kmin1, u_sim[:,k-1])\n",
    "    m_k,S_k = correct(agent, y_sim[:,k], m_k_pred, S_k_pred, approx=\"ET2\")\n",
    "    \n",
    "    # Compute model evidence\n",
    "    F_EFER[k] = evidence(agent, y_sim[:,k], m_k, S_k, approx=\"ET2\")\n",
    "    J_EFER[k] = -logpdf(MvNormal(goal[1], goal[2]), y_sim[:,k])\n",
    "    \n",
    "    # Store state estimates\n",
    "    z_est[1][:,k] = m_k\n",
    "    z_est[2][:,:,k] = S_k\n",
    "    \n",
    "    \"Planning\"\n",
    "    \n",
    "    # Single-argument objective\n",
    "    G(u::AbstractVector) = EFE(agent, u, (m_k,S_k), approx=\"ET2\", add_ambiguity=false)\n",
    "    \n",
    "    # Call minimizer using constrained L-BFGS procedure\n",
    "    results = Optim.optimize(G, u_lims[1], u_lims[2], zeros(2*len_horizon), Fminbox(LBFGS()), opts; autodiff=:forward)\n",
    "    \n",
    "    # Extract minimizing control\n",
    "    policy = reshape(Optim.minimizer(results), (2,len_horizon))\n",
    "    u_sim[:,k] = policy[:,1]\n",
    "\n",
    "    # Planning\n",
    "    planned_states, planned_obs = planned_trajectory(agent, policy, (m_k,S_k), approx=\"ET2\")\n",
    "    z_pln[1][k,:,:]   = planned_states[1]\n",
    "    z_pln[2][k,:,:,:] = planned_states[2] \n",
    "    y_pln[1][k,:,:]   = planned_obs[1]\n",
    "    y_pln[2][k,:,:,:] = planned_obs[2]\n",
    "   \n",
    "    # Update recursion\n",
    "    m_kmin1 = m_k\n",
    "    S_kmin1 = S_k\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eab879",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim = @animate for k in 3:len_trial\n",
    "    p301 = plot(size=(800,800), legend=:topleft, aspect_ratio=:equal, ylabel=\"position y\", xlabel=\"position x\", xlims=xl, ylims=yl)\n",
    "    scatter!([z_0[1]], [z_0[2]], color=\"blue\", label=\"start\", markersize=5)\n",
    "    scatter!([z_star[1]], [z_star[2]], color=\"red\", label=\"goal state\", markersize=5)\n",
    "    \n",
    "    plot!(z_sim[1,2:k], z_sim[2,2:k], c=\"blue\", label=\"true\", alpha=0.5)\n",
    "    plot!(z_est[1][1,2:k], z_est[1][2,2:k], c=\"purple\", label=\"inferred\", alpha=0.5)\n",
    "    covellipse!(z_est[1][1:2,k], z_est[2][1:2,1:2,k], n_std=1, color=\"purple\", linewidth=0, fillalpha=0.3)\n",
    "    \n",
    "    plot!(z_pln[1][k,1,:], z_pln[1][k,2,:], c=\"orange\", label=\"planned\")\n",
    "    for j in 1:len_horizon\n",
    "        covellipse!(z_pln[1][k,1:2,j], z_pln[2][k,1:2,1:2,j], n_std=1, color=\"orange\", linewidth=0, fillalpha=0.3)\n",
    "    end\n",
    "end\n",
    "gif(anim, \"animations/cart2polar-experiment-EFER-path.gif\", fps=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p301 = plot(size=(800,500), legend=:topleft, ylabel=\"position y\", xlabel=\"position x\", xlims=xl, ylims=yl)\n",
    "scatter!([z_0[1]], [z_0[2]], color=\"green\", marker=:diamond, label=\"start\", markersize=8)\n",
    "scatter!([z_star[1]], [z_star[2]], color=\"green\", label=\"goal\", markersize=8)\n",
    "\n",
    "plot!(z_sim[1,:], z_sim[2,:], c=\"blue\", label=\"true\")    \n",
    "plot!(z_est[1][1,:], z_est[1][2,:], c=\"purple\", label=\"inferred\")\n",
    "\n",
    "for j in 1:len_trial\n",
    "    covellipse!(z_est[1][1:2,j], z_est[2][1:2,1:2,j], n_std=1, color=\"purple\", linewidth=0, fillalpha=0.1)\n",
    "end\n",
    "plot!()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"figures/cart2polar-experiment-EFER-path.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015bb5c7",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbc2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"F EFE2 = $tF_EFE2\")\n",
    "println(\"F EFE1 = $tF_EFE1\")\n",
    "println(\"F EFER = $tF_EFER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08280fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tJ_EFE2 = sum(J_EFE2)\n",
    "tJ_EFE1 = sum(J_EFE1)\n",
    "tJ_EFER = sum(J_EFER)\n",
    "\n",
    "println(\"Total goal prior -log-likelihood EFE2 = $tJ_EFE2\")\n",
    "println(\"Total goal prior -log-likelihood EFE1 = $tJ_EFE1\")\n",
    "println(\"Total goal prior -log-likelihood EFER = $tJ_EFER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_EFE2 = sum(F_EFE2) + sum(J_EFE2)\n",
    "perf_EFE1 = sum(F_EFE1) + sum(J_EFE1)\n",
    "perf_EFER = sum(F_EFER) + sum(J_EFER)\n",
    "\n",
    "println(\"Performance EFE2 = $perf_EFE2\")\n",
    "println(\"Performance EFE1 = $perf_EFE1\")\n",
    "println(\"Performance EFER = $perf_EFER\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
